{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac7ba50e",
   "metadata": {},
   "source": [
    "LangChain 프롬프트 템플릿\n",
    "```\n",
    "LLM 프롬프트를 동적으로 구성하고 재사용 할 수 있도록 해주는 도구\n",
    "    단일입력 : 하나의 변수로 구성된 프롬프트 템플릿\n",
    "    다중입력 : 둘 이상의 변수를 사용하는 템플릿\n",
    "    ChatPromptTemplate 역할 기반 프롬프트 : 시스템 / 사용자 역할별 프롬프트 구성  .from_message()\n",
    "    PartialPeomptTemplate 활용 : 프롬프트 일부를 고정하고 부분 포멧팅을 사용 (ex. 시스템 메세지는 고정..)\n",
    "    프롬프트 출력 및 체인 실행 : LCEL기법\n",
    "    프롬프트 작성 팁 : 주의사항 및 모범사례 \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4caa2663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 환경설정\n",
    "%pip install langchain langchain-openai python-dotenv --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bc47f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e518c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "당신은 최고 수준의 마케팅 카피아리터 입니다.\n",
      "아래 제품에 대한 매력적인 홍보문구를 100자 내외로 작성해 주세요. \n",
      "\n",
      "제품명 : 이클립스\n"
     ]
    }
   ],
   "source": [
    "# 단일 프롬프트(그냥 from_template) 사용\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# 템플릿 문자열 정의\n",
    "template_str = (\n",
    "    \"당신은 최고 수준의 마케팅 카피아리터 입니다.\\n\"\n",
    "    \"아래 제품에 대한 매력적인 홍보문구를 100자 내외로 작성해 주세요. \\n\\n\"\n",
    "    \"제품명 : {product_name}\"\n",
    ")\n",
    "\n",
    "# 프롬프트 템플릿 객체 생성\n",
    "product_prompt = PromptTemplate.from_template(template_str)\n",
    "\n",
    "# 템플릿에 값 채우기 \n",
    "formatted_prompt = product_prompt.format(product_name='이클립스')\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8e84f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"이클립스, 당신의 일상에 빛나는 변화를! 매일의 순간을 특별하게 만들어주는 완벽한 선택. 지금 경험해보세요!\"\n"
     ]
    }
   ],
   "source": [
    "# llm에 연결하기\n",
    "# LCEL\n",
    "# 프롬프트 | llm  => invoke 사용\n",
    "\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model = 'gpt-4o-mini', temperature = 0)\n",
    "\n",
    "# Runnable객체 생성 LCEL\n",
    "chain = product_prompt |llm\n",
    "result = chain.invoke({'product_name': '이클립스'})\n",
    "print(result.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "faac000d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아래는 뉴스 기사 제목과 키워드 입니다. \n",
      "이 정보를 바탕으로 한 문단으로 구성된 간략한 요약문을 작성하세요 \n",
      "\n",
      "제목 : 인공지능 기술의 발전과 미래키워드 : 머신러닝, 딥러닝, LLM, 랭체인, 산업 혁신\n"
     ]
    }
   ],
   "source": [
    "# 다중 입력(단일은 from_template 사용했지만 다중은 생성자를 이용하는게 좋음)\n",
    "# 다중입력 템플릿 문자열 정의\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "multi_template_str = (\n",
    "    '아래는 뉴스 기사 제목과 키워드 입니다. \\n'\n",
    "    '이 정보를 바탕으로 한 문단으로 구성된 간략한 요약문을 작성하세요 \\n\\n'\n",
    "    '제목 : {title}'\n",
    "    '키워드 : {keyword}'\n",
    ")\n",
    "\n",
    "# 프롬프트 템플릿 \n",
    "summary_prompt = PromptTemplate(template=multi_template_str, input_variables=['title','keyword'])\n",
    "\n",
    "# 포멧팅을 통해 프롬프트 값 확인\n",
    "sample_title = '인공지능 기술의 발전과 미래'\n",
    "sample_keyword = '머신러닝, 딥러닝, LLM, 랭체인, 산업 혁신'\n",
    "formatted_summary_prompt = summary_prompt.format(title = sample_title, keyword = sample_keyword)\n",
    "print(formatted_summary_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cffa5b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='인공지능 기술의 발전은 머신러닝과 딥러닝의 혁신을 통해 가속화되고 있으며, 특히 대규모 언어 모델(LLM)과 랭체인 기술이 주목받고 있습니다. 이러한 기술들은 다양한 산업 분야에서 혁신을 이끌어내고 있으며, 기업들은 이를 활용하여 효율성을 높이고 새로운 비즈니스 모델을 창출하고 있습니다. 앞으로 인공지능은 더욱 발전하여 우리의 삶과 산업 구조에 큰 변화를 가져올 것으로 기대됩니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 111, 'prompt_tokens': 76, 'total_tokens': 187, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_62a23a81ef', 'id': 'chatcmpl-BbKhBxxdZPzS5tGBFqjrOJGaVlE74', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--30b516a7-304f-445b-8c33-3901a3002864-0', usage_metadata={'input_tokens': 76, 'output_tokens': 111, 'total_tokens': 187, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LCEL 출력\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser = StrOutputParser()\n",
    "result_summary = (summary_prompt | llm ).invoke({\n",
    "    'title': sample_title,\n",
    "    'keyword': sample_keyword\n",
    "})\n",
    "result_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a22577e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatPromptTemplate과 역할 기반 프롬프트\n",
    "# 시스템/사용자/어시스턴트 역할 (role)을 포함한 다중 템플릿을 구성하는 프롬프트\n",
    "# 시스템 메시지: 모델의 동작을 지시\n",
    "# 사용자 메시지: 실제 사용자의 입력\n",
    "# 어시스턴트 메시지: 이전 모델이 응답한 내용이 있다면 대화 맥락 유지를 위해 활용 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72b4b51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='당신은 python 분야의 뛰어난 전문가이자 조언자 입니다.사용자의 프로그래밍 질문에 대해 친절하고 이해하기 쉽게 답변해 주세요', additional_kwargs={}, response_metadata={}), HumanMessage(content='파이선의 클래스에 대해서 설명해주세요', additional_kwargs={}, response_metadata={})]\n",
      "파이썬의 클래스는 객체 지향 프로그래밍(OOP)의 기본 개념 중 하나로, 객체를 생성하기 위한 청print(blueprint)입니다. 클래스는 속성(데이터)과 메서드(함수)를 포함할 수 있으며, 이를 통해 관련된 데이터와 기능을 하나의 단위로 묶을 수 있습니다.\n",
      "\n",
      "### 클래스의 기본 구조\n",
      "\n",
      "클래스를 정의하려면 `class` 키워드를 사용합니다. 다음은 간단한 클래스의 예입니다:\n",
      "\n",
      "```python\n",
      "class Dog:\n",
      "    # 생성자 메서드\n",
      "    def __init__(self, name, age):\n",
      "        self.name = name  # 인스턴스 변수\n",
      "        self.age = age    # 인스턴스 변수\n",
      "\n",
      "    # 메서드\n",
      "    def bark(self):\n",
      "        return f\"{self.name} says woof!\"\n",
      "\n",
      "# 클래스의 인스턴스 생성\n",
      "my_dog = Dog(\"Buddy\", 3)\n",
      "\n",
      "# 인스턴스 메서드 호출\n",
      "print(my_dog.bark())  # 출력: Buddy says woof!\n",
      "```\n",
      "\n",
      "### 주요 개념\n",
      "\n",
      "1. **생성자 (`__init__` 메서드)**:\n",
      "   - 클래스의 인스턴스가 생성될 때 호출되는 특별한 메서드입니다.\n",
      "   - 인스턴스 변수(속성)를 초기화하는 데 사용됩니다.\n",
      "\n",
      "2. **인스턴스 변수**:\n",
      "   - 각 인스턴스(객체)마다 고유한 데이터를 저장하는 변수입니다.\n",
      "   - `self` 키워드를 사용하여 인스턴스 변수를 정의합니다.\n",
      "\n",
      "3. **메서드**:\n",
      "   - 클래스 내에서 정의된 함수로, 인스턴스의 데이터를 조작하거나 특정 작업을 수행합니다.\n",
      "   - 첫 번째 매개변수로 항상 `self`를 받아야 하며, 이를 통해 인스턴스의 속성에 접근할 수 있습니다.\n",
      "\n",
      "4. **인스턴스 생성**:\n",
      "   - 클래스를 사용하여 객체를 생성할 수 있습니다. 이때 클래스 이름을 함수처럼 호출합니다.\n",
      "\n",
      "5. **상속**:\n",
      "   - 클래스는 다른 클래스로부터 속성과 메서드를 상속받을 수 있습니다. 이를 통해 코드의 재사용성을 높일 수 있습니다.\n",
      "\n",
      "### 예제: 상속\n",
      "\n",
      "```python\n",
      "class Animal:\n",
      "    def speak(self):\n",
      "        return \"Animal speaks\"\n",
      "\n",
      "class Cat(Animal):  # Animal 클래스를 상속받음\n",
      "    def speak(self):\n",
      "        return \"Meow\"\n",
      "\n",
      "my_cat = Cat()\n",
      "print(my_cat.speak())  # 출력: Meow\n",
      "```\n",
      "\n",
      "### 요약\n",
      "\n",
      "- 클래스는 객체를 생성하기 위한 설계도입니다.\n",
      "- 속성과 메서드를 통해 관련된 데이터와 기능을 묶을 수 있습니다.\n",
      "- 객체 지향 프로그래밍의 원칙을 따르며, 코드의 재사용성과 유지보수성을 높이는 데 도움을 줍니다.\n",
      "\n",
      "클래스에 대해 더 궁금한 점이 있으면 언제든지 질문해 주세요!\n"
     ]
    }
   ],
   "source": [
    "system_message = ('당신은 python 분야의 뛰어난 전문가이자 조언자 입니다.'\n",
    "                  '사용자의 프로그래밍 질문에 대해 친절하고 이해하기 쉽게 답변해 주세요')\n",
    "user_message = '{question}'\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', system_message),\n",
    "    ('user', user_message)\n",
    "])\n",
    "\n",
    "# 템플릿을 이용해서 문장을 완성해 보세요 => 사용법을 알기위해서 하는것 llm에서는 사용 안함\n",
    "sample_question = '파이선의 클래스에 대해서 설명해주세요'\n",
    "formated_message = chat_prompt.format_messages(question=sample_question)\n",
    "print(formated_message)\n",
    "\n",
    "# 파이프라인을 이용해서 llm 호출 및 출력\n",
    "answer = (chat_prompt | llm | parser).invoke({'question': sample_question})\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "206123f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ParitalPtomptTemplate : 템플릿의 일부를 부분적으로 채운 새로운 탬플릿\n",
    "from langchain.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "role_system_template = '당신은 {role} 분야의 전문 지식인 입니다. 가능한 자세히 답변해 주세요'\n",
    "system_prompt = SystemMessagePromptTemplate.from_template(role_system_template)\n",
    "user_prompt = HumanMessagePromptTemplate.from_template('{question}')\n",
    "\n",
    "# chatprompttemplate을 생성\n",
    "base_chat_prompt = ChatPromptTemplate.from_messages([system_prompt, user_prompt])\n",
    "partial_chat_prompt =  base_chat_prompt.partial(role = '주식투자')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b528e835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='당신은 주식투자 분야의 전문 지식인 입니다. 가능한 자세히 답변해 주세요', additional_kwargs={}, response_metadata={}), HumanMessage(content='현재 2025년 5월 시장 상황에서 삼성전자 주식 전망은', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "#partial로 생성된 프롬프트에 질문만 채워 프롬프트 구성\n",
    "sample_question = \"현재 2025년 5월 시장 상황에서 삼성전자 주식 전망은\"\n",
    "message = partial_chat_prompt.format_messages(question=sample_question)\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12b9dbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025년 5월의 삼성전자 주식 전망을 평가하기 위해서는 여러 가지 요소를 고려해야 합니다. 다음은 삼성전자의 주식 전망에 영향을 미칠 수 있는 주요 요인들입니다.\n",
      "\n",
      "1. **반도체 시장 동향**: 삼성전자는 세계 최대의 반도체 제조업체 중 하나입니다. 반도체 수요는 AI, IoT, 5G 등 다양한 기술 발전에 따라 증가하고 있습니다. 2025년에는 이러한 기술들이 더욱 발전할 것으로 예상되며, 이에 따라 반도체 수요가 증가할 가능성이 높습니다. 그러나 반도체 시장은 경기 사이클에 민감하므로, 글로벌 경제 상황에 따라 변동성이 클 수 있습니다.\n",
      "\n",
      "2. **스마트폰 및 가전제품 판매**: 삼성전자는 스마트폰과 가전제품에서도 강력한 입지를 가지고 있습니다. 2025년에는 새로운 모델과 혁신적인 기술이 출시될 가능성이 있으며, 이는 매출 증가에 긍정적인 영향을 미칠 수 있습니다. 특히, 폴더블 스마트폰과 같은 새로운 형태의 제품이 소비자에게 인기를 끌 수 있습니다.\n",
      "\n",
      "3. **글로벌 경제 상황**: 글로벌 경제의 성장률, 금리, 인플레이션 등은 삼성전자의 주가에 큰 영향을 미칠 수 있습니다. 경제가 안정적이고 성장세를 보인다면 소비자 지출이 증가하고, 이는 삼성전자의 매출 증가로 이어질 수 있습니다.\n",
      "\n",
      "4. **경쟁 상황**: 삼성전자는 애플, 화웨이, TSMC 등과 같은 강력한 경쟁자들과 경쟁하고 있습니다. 이들 기업의 기술 발전과 시장 점유율 변화는 삼성전자의 주가에 영향을 미칠 수 있습니다.\n",
      "\n",
      "5. **정치적 및 규제 환경**: 한국과 글로벌 시장에서의 정치적 안정성, 무역 정책, 규제 변화 등도 삼성전자의 운영에 영향을 미칠 수 있습니다. 특히, 반도체 산업은 국가 간의 무역 갈등에 민감하므로, 이러한 요소를 주의 깊게 살펴봐야 합니다.\n",
      "\n",
      "6. **ESG(환경, 사회, 지배구조) 경영**: 최근 투자자들은 ESG 요소를 중요하게 고려하고 있습니다. 삼성전자가 지속 가능한 경영을 통해 긍정적인 이미지를 구축하고, 이에 따라 투자자들의 신뢰를 얻는다면 주가에 긍정적인 영향을 미칠 수 있습니다.\n",
      "\n",
      "결론적으로, 삼성전자의 주식 전망은 긍정적일 수 있지만, 여러 외부 요인에 따라 변동성이 클 수 있습니다. 따라서, 투자 결정을 내리기 전에 충분한 시장 조사와 분석이 필요합니다.\n"
     ]
    }
   ],
   "source": [
    "# LCEL - invoke\n",
    "answer = (partial_chat_prompt | llm | parser).invoke({'question':sample_question})\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3a65fd",
   "metadata": {},
   "source": [
    "```\n",
    "이전 대화 내용을 기억해서 문맥을 유지하는 역할\n",
    "LangChain 0.3x부터는 LCEL 기반으로 체인을 구성\n",
    "RunnableWithMessageHistory , ChatMessageHistory 등의 컴포넌트를 활용해서 세션별 대화 기록을 관리\n",
    "대화가 장기화될 경우 요약 메모리를 도입해서 과거 대화를 LLM으로 요약하고 축약된 형태로 저장해서 프롬프트의 길이문제를 해결\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2d008f",
   "metadata": {},
   "source": [
    "```\n",
    "%pip install langchain langchain-openai python-dotenv langchain_redis --quiet 로 인스톨하고 \n",
    "env환경 가져와야하니까 from dotenv import load_dotenv 해줌\n",
    "랭체인 코어에 점 하면 챗 히스토리가 있음.\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cd947c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain-openai python-dotenv langchain_redis --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ae3590d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c95641",
   "metadata": {},
   "source": [
    "코드에 있는 msg.type과 msg.content는 Langchain의 ChatMessage 객체가 갖고 있는 속성(attributes)\n",
    "\n",
    "🔍 msg.type\n",
    "누가 보낸 메시지인지를 나타내는 문자열\n",
    "주로 두 가지 값 중 하나가 나와:\n",
    "\"human\" → 사용자가 보낸 메시지\n",
    "\"ai\" → AI가 보낸 메시지\n",
    "👉 즉, 사람/AI 구분용이야.\n",
    "\n",
    "🔍 msg.content\n",
    "실제 메시지 본문 내용, 즉 텍스트 문자열이야."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8b031339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human : 안녕하세요 제 이름은 홍길동 입니다.\n",
      "ai : 안녕하세요 홍길동님, 무엇을 도와드릴까요?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.chat_history import  InMemoryChatMessageHistory\n",
    "# 메모리 객체 생성\n",
    "history =  InMemoryChatMessageHistory()\n",
    "history.add_user_message(\"안녕하세요 제 이름은 홍길동 입니다.\")\n",
    "history.add_ai_message('안녕하세요 홍길동님, 무엇을 도와드릴까요?')\n",
    "# 현재까지의 대화 내용 확인\n",
    "for msg in history.messages:\n",
    "    print(f'{msg.type} : {msg.content}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a521de68",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "Error 10061 connecting to localhost:6379. 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectionRefusedError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\.conda\\envs\\llm\\Lib\\site-packages\\redis\\connection.py:378\u001b[39m, in \u001b[36mAbstractConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdisconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m socket.timeout:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\.conda\\envs\\llm\\Lib\\site-packages\\redis\\retry.py:62\u001b[39m, in \u001b[36mRetry.call_with_retry\u001b[39m\u001b[34m(self, do, fail)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mself\u001b[39m._supported_errors \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\.conda\\envs\\llm\\Lib\\site-packages\\redis\\connection.py:379\u001b[39m, in \u001b[36mAbstractConnection.connect.<locals>.<lambda>\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    378\u001b[39m     sock = \u001b[38;5;28mself\u001b[39m.retry.call_with_retry(\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mlambda\u001b[39;00m error: \u001b[38;5;28mself\u001b[39m.disconnect(error)\n\u001b[32m    380\u001b[39m     )\n\u001b[32m    381\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m socket.timeout:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\.conda\\envs\\llm\\Lib\\site-packages\\redis\\connection.py:764\u001b[39m, in \u001b[36mConnection._connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    763\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m    765\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33msocket.getaddrinfo returned an empty list\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\.conda\\envs\\llm\\Lib\\site-packages\\redis\\connection.py:752\u001b[39m, in \u001b[36mConnection._connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    751\u001b[39m \u001b[38;5;66;03m# connect\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m752\u001b[39m \u001b[43msock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msocket_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    754\u001b[39m \u001b[38;5;66;03m# set the socket_timeout now that we're connected\u001b[39;00m\n",
      "\u001b[31mConnectionRefusedError\u001b[39m: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mConnectionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[81]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m REDIS_URL = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mREDIS_URL\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mredis://localhost:6379\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m session_id = \u001b[33m'\u001b[39m\u001b[33muser_123\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m history =  \u001b[43mRedisChatMessageHistory\u001b[49m\u001b[43m(\u001b[49m\u001b[43msession_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43msession_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mredis_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mREDIS_URL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m history.add_user_message(\u001b[33m\"\u001b[39m\u001b[33m안녕하세요 제 이름은 홍길동 입니다.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m history.add_ai_message(\u001b[33m'\u001b[39m\u001b[33m안녕하세요 홍길동님, 무엇을 도와드릴까요?\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\.conda\\envs\\llm\\Lib\\site-packages\\langchain_redis\\chat_message_history.py:120\u001b[39m, in \u001b[36mRedisChatMessageHistory.__init__\u001b[39m\u001b[34m(self, session_id, redis_url, key_prefix, ttl, index_name, redis_client, **kwargs)\u001b[39m\n\u001b[32m    118\u001b[39m     \u001b[38;5;28mself\u001b[39m.redis_client.pubsub_configs = {\u001b[33m\"\u001b[39m\u001b[33mpush_handler_func\u001b[39m\u001b[33m\"\u001b[39m: _noop_push_handler}\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mredis_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclient_setinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mLIB-NAME\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m__full_lib_name__\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ResponseError:\n\u001b[32m    122\u001b[39m     \u001b[38;5;66;03m# Fall back to a simple log echo\u001b[39;00m\n\u001b[32m    123\u001b[39m     \u001b[38;5;28mself\u001b[39m.redis_client.echo(__full_lib_name__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\.conda\\envs\\llm\\Lib\\site-packages\\redis\\commands\\core.py:709\u001b[39m, in \u001b[36mManagementCommands.client_setinfo\u001b[39m\u001b[34m(self, attr, value, **kwargs)\u001b[39m\n\u001b[32m    704\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclient_setinfo\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr: \u001b[38;5;28mstr\u001b[39m, value: \u001b[38;5;28mstr\u001b[39m, **kwargs) -> ResponseT:\n\u001b[32m    705\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    706\u001b[39m \u001b[33;03m    Sets the current connection library name or version\u001b[39;00m\n\u001b[32m    707\u001b[39m \u001b[33;03m    For mor information see https://redis.io/commands/client-setinfo\u001b[39;00m\n\u001b[32m    708\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m709\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute_command\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCLIENT SETINFO\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\.conda\\envs\\llm\\Lib\\site-packages\\redis\\client.py:605\u001b[39m, in \u001b[36mRedis.execute_command\u001b[39m\u001b[34m(self, *args, **options)\u001b[39m\n\u001b[32m    604\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute_command\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **options):\n\u001b[32m--> \u001b[39m\u001b[32m605\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\.conda\\envs\\llm\\Lib\\site-packages\\redis\\client.py:611\u001b[39m, in \u001b[36mRedis._execute_command\u001b[39m\u001b[34m(self, *args, **options)\u001b[39m\n\u001b[32m    609\u001b[39m pool = \u001b[38;5;28mself\u001b[39m.connection_pool\n\u001b[32m    610\u001b[39m command_name = args[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m611\u001b[39m conn = \u001b[38;5;28mself\u001b[39m.connection \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    613\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._single_connection_client:\n\u001b[32m    614\u001b[39m     \u001b[38;5;28mself\u001b[39m.single_connection_lock.acquire()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\.conda\\envs\\llm\\Lib\\site-packages\\redis\\utils.py:183\u001b[39m, in \u001b[36mdeprecated_args.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m provided_args:\n\u001b[32m    179\u001b[39m         warn_deprecated_arg_usage(\n\u001b[32m    180\u001b[39m             arg, func.\u001b[34m__name__\u001b[39m, reason, version, stacklevel=\u001b[32m3\u001b[39m\n\u001b[32m    181\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\.conda\\envs\\llm\\Lib\\site-packages\\redis\\connection.py:1483\u001b[39m, in \u001b[36mConnectionPool.get_connection\u001b[39m\u001b[34m(self, command_name, *keys, **options)\u001b[39m\n\u001b[32m   1479\u001b[39m     \u001b[38;5;28mself\u001b[39m._in_use_connections.add(connection)\n\u001b[32m   1481\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1482\u001b[39m     \u001b[38;5;66;03m# ensure this connection is connected to Redis\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1483\u001b[39m     \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1484\u001b[39m     \u001b[38;5;66;03m# connections that the pool provides should be ready to send\u001b[39;00m\n\u001b[32m   1485\u001b[39m     \u001b[38;5;66;03m# a command. if not, the connection was either returned to the\u001b[39;00m\n\u001b[32m   1486\u001b[39m     \u001b[38;5;66;03m# pool before all data has been read or the socket has been\u001b[39;00m\n\u001b[32m   1487\u001b[39m     \u001b[38;5;66;03m# closed. either way, reconnect and verify everything is good.\u001b[39;00m\n\u001b[32m   1488\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\.conda\\envs\\llm\\Lib\\site-packages\\redis\\connection.py:384\u001b[39m, in \u001b[36mAbstractConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    382\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTimeout connecting to server\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(\u001b[38;5;28mself\u001b[39m._error_message(e))\n\u001b[32m    386\u001b[39m \u001b[38;5;28mself\u001b[39m._sock = sock\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mConnectionError\u001b[39m: Error 10061 connecting to localhost:6379. 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다."
     ]
    }
   ],
   "source": [
    "# Radis 기반 채팅 기록 저장소\n",
    "from langchain_redis import RedisChatMessageHistory\n",
    "import os\n",
    "REDIS_URL = os.getenv(\"REDIS_URL\", \"redis://localhost:6379\")\n",
    "session_id = 'user_123'\n",
    "history =  RedisChatMessageHistory(session_id=session_id, redis_url=REDIS_URL)\n",
    "history.add_user_message(\"안녕하세요 제 이름은 홍길동 입니다.\")\n",
    "history.add_ai_message('안녕하세요 홍길동님, 무엇을 도와드릴까요?')\n",
    "# 현재까지의 대화 내용 확인\n",
    "for msg in history.messages:\n",
    "    print(f'{msg.type} : {msg.content}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b4bd418f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세션기반 다중사용자 메모리 구조 구현 - 다중사용자 챗봇\n",
    "# 핵심 :session_id를 키로 하는 메모리 저장소만들고 사용자의 대화는 키별로 저장한다.\n",
    "from langchain_core.prompts import  ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "# 프롬프트\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",'당신은 뛰어난 한국어 상담 챗봇입니다 질문에 친절하고 자세히 답변해주세요'),\n",
    "    # history키로 전달된 메세지 목록은 체인 실행시 해당 위치에 넣겠다는 의미\n",
    "    MessagesPlaceholder(variable_name='history'), \n",
    "    ('human','{input}')\n",
    "])\n",
    "llm = ChatOpenAI(model='gpt-4o-mini',temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4eb14594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LCEL\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "84e3edee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세션별 메모리 저장소를 딕셔너리로 만들고, 존재하지 않는 새로운 세션 id가 들어오면 InMemoryChatMessageHistory를 생성\n",
    "# get_session_history를 구현\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dc15c51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "# 세션 id -> 대화 기록 객체 매핑\n",
    "store = {}\n",
    "def get_session_history(session_id: str) -> InMemoryChatMessageHistory:\n",
    "    '''\"세션 ID\"에 해당하는 대화 기록 객체를 반환합니다.(없으면 새로 생성)'''\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# 메모리를 통합한 체인 래퍼 생성\n",
    "chatbot = RunnableWithMessageHistory(    \n",
    "    chain,\n",
    "    get_session_history,    \n",
    "    input_messages_key = 'input',\n",
    "    history_messages_key = 'history'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "41ef23eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:48:15 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[user_a] 질문: 안녕하세요, 저는 홍길동입니다. 당신은 누구신가요?\n",
      "[user_a] 챗봇: 안녕하세요, 홍길동님! 저는 여러분의 질문에 답변하고 도움을 드리기 위해 만들어진 챗봇입니다. 어떤 궁금한 점이나 도움이 필요하신 부분이 있으신가요?\n",
      "\n",
      "17:48:17 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[user_b] 질문: 안녕하세요, 저는 이순신입니다. 당신은 어떤 일을 하시나요?\n",
      "[user_b] 챗봇: 안녕하세요, 이순신님! 저는 여러분의 질문에 답변하고, 정보 제공, 상담 등을 도와주는 챗봇입니다. 궁금한 점이나 도움이 필요한 부분이 있다면 언제든지 말씀해 주세요!\n",
      "\n",
      "17:48:19 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[user_a] 질문: 저는 프로그래밍을 배우고 있습니다. 당신은 어떤 일을 하시나요?\n",
      "[user_a] 챗봇: 프로그래밍을 배우고 계시다니 멋지네요! 저는 여러분의 질문에 답변하고, 정보 제공, 문제 해결, 그리고 다양한 주제에 대한 상담을 하는 역할을 하고 있습니다. 프로그래밍에 관련된 질문이나 도움이 필요하시면 언제든지 말씀해 주세요! 어떤 언어를 배우고 계신가요?\n",
      "\n",
      "17:48:20 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[user_b] 질문: 저는 역사에 관심이 많습니다. 당신은 어떤 분야에 관심이 있나요?\n",
      "[user_b] 챗봇: 역사에 관심이 많으시다니 정말 멋지네요! 저는 특정한 관심 분야가 없지만, 다양한 주제에 대한 정보를 제공할 수 있습니다. 역사, 과학, 기술, 문화 등 여러 분야에 대해 이야기할 수 있으니, 궁금한 점이나 더 알고 싶은 주제가 있다면 말씀해 주세요!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 두개의 세션을 번갈아가면서 대화  RunnableWithMessageHistory 가 각 세션에 맞는 대화 기록을 관리합니다.\n",
    "sessions = ['user_a','user_b']\n",
    "questions = [\n",
    "    '안녕하세요, 저는 홍길동입니다. 당신은 누구신가요?',   # usre_a 첫번재 질문\n",
    "    '안녕하세요, 저는 이순신입니다. 당신은 어떤 일을 하시나요?', # user_b 첫번째 질문\n",
    "    '저는 프로그래밍을 배우고 있습니다. 당신은 어떤 일을 하시나요?', # user_a 두번째 질문\n",
    "    '저는 역사에 관심이 많습니다. 당신은 어떤 분야에 관심이 있나요?' # user_b 두번째 질문\n",
    "]\n",
    "for i, question in enumerate(questions):\n",
    "    session_id = sessions[i % 2]  # 세션 ID를 번갈아가며 사용\n",
    "    result = chatbot.invoke({'input': question}, config={'configurable': {'session_id': session_id}})\n",
    "    print(f'[{session_id}] 질문: {question}')\n",
    "    print(f'[{session_id}] 챗봇: {result}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "955d0b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:48:22 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[user_c] 질문: 저는 철수예요, 반갑습니다.\n",
      "[user_c] 챗봇: 안녕하세요, 철수님! 반갑습니다. 어떻게 도와드릴까요? 궁금한 점이나 이야기하고 싶은 주제가 있다면 말씀해 주세요.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = chatbot.invoke({'input':\"저는 철수예요, 반갑습니다\"}, config={'configurable' : {'session_id' : 'user_c'}})\n",
    "print(f'[user_c] 질문: 저는 철수예요, 반갑습니다.')\n",
    "print(f'[user_c] 챗봇: {result}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fd8bb715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:48:23 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'홍길동님이라고 말씀하셨습니다! 혹시 더 궁금한 점이나 다른 질문이 있으신가요? 도움이 필요하시면 언제든지 말씀해 주세요.'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = chatbot.invoke({'input':\"저는 누구라고요?\"}, config={'configurable' : {'session_id' : 'user_a'}})\n",
    "# user_a인 홍길동과의 과거 기록을 토대로 ' 당신은 홍길동입니다'라고 대답해야함\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3c32afd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:48:25 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[user_c] 질문: 저는 철수예요, 반갑습니다.\n",
      "[user_c] 챗봇: 안녕하세요, 철수님! 다시 만나서 반갑습니다. 오늘은 어떤 이야기를 나누고 싶으신가요? 궁금한 점이나 도움이 필요한 부분이 있다면 말씀해 주세요!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = chatbot.invoke({'input':\"저는 철수예요, 반갑습니다\"}, config={'configurable' : {'session_id' : 'user_c'}})\n",
    "print(f'[user_c] 질문: 저는 철수예요, 반갑습니다.')\n",
    "print(f'[user_c] 챗봇: {result}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93f6bd6",
   "metadata": {},
   "source": [
    "요약 메모리 구현(대화내용 자동 요약)\n",
    "```\n",
    "긴 대화내용을 모두 프롬프트에 기록하는 것은 비효율적 -> 프롬프트의 길이 제한에 걸릴 가능성이 있음\n",
    "Conversation Summary Memory\n",
    "0.3x 버전에서는 직접 요약용 체인을 만들어서 ChatMessageHistory에 적용\n",
    "```\n",
    "\n",
    "어떻게 요약?\n",
    "```\n",
    "- 일정길이 이상으로 대화가 누적되면, 과거 대화를 요약해서 핵심 내용만 남김\n",
    "- 요약 결과를 메모리에 시스템 메시지 등으로 저장 -> 메모리 절약\n",
    "- 새로운 사용자 입력시 요약된 맥락 + 최근 몇 메시지만 참고해서 llm 전달\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "efa4c63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요약용 프롬프트 템플릿\n",
    "summary_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 대화 요약 전문가입니다. 대화의 주요 내용을 간결하게 요약해 주세요\"),\n",
    "    (\"human\",\"{conversation}\") #전체 대화내용을 하나의 문자열로 전달\n",
    "])\n",
    "# LCEL\n",
    "summary_chain = summary_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9843dfee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:48:27 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "17:48:28 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "17:48:30 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "17:48:33 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "17:48:36 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "요약전 user_d의 메모리 메세지 개수: 10\n",
      "Human: 안녕, 오늘 우리 뭐하려고 했지?\n",
      "AI: 안녕하세요! 오늘 어떤 이야기를 나누고 싶으신가요? 궁금한 점이나 하고 싶은 주제가 있다면 말씀해 주세요. 함께 이야기해보아요!\n",
      "Human: 아 맞다 내일 회의자료 준비해야지, 회의는 몇시지?\n",
      "AI: 회의 시간이 기억나지 않으신가요? 회의 일정은 보통 이메일이나 캘린더에 기록되어 있을 텐데요. 확인해보시고, 필요한 자료나 준비물도 함께 점검해보시면 좋을 것 같아요. 혹시 회의 자료 준비에 도움이 필요하시면 말씀해 주세요!\n",
      "Human: 그 회의에 누가 참석하는지 기억나니?\n",
      "AI: 회의 참석자에 대한 정보는 제가 알 수 없지만, 보통 회의 초대 이메일이나 캘린더에 참석자 목록이 포함되어 있을 거예요. 그곳에서 확인해보시면 좋을 것 같습니다. 만약 참석자 목록을 정리하거나 회의 자료를 준비하는 데 도움이 필요하시면 말씀해 주세요!\n",
      "Human: 단위 프로젝트 진행 상황도 공유해야 할까?\n",
      "AI: 네, 단위 프로젝트 진행 상황을 공유하는 것은 좋은 아이디어입니다. 팀원들이 현재 진행 중인 작업이나 성과를 파악하는 데 도움이 되고, 필요한 지원이나 피드백을 받을 수 있는 기회가 될 수 있습니다. \n",
      "\n",
      "회의에서 공유할 내용을 정리할 때는 다음과 같은 사항을 포함하면 좋습니다:\n",
      "\n",
      "1. **프로젝트 목표**: 현재 진행 중인 프로젝트의 목표를 간단히 설명합니다.\n",
      "2. **진행 상황**: 현재까지의 진행 상황과 완료된 작업을 요약합니다.\n",
      "3. **문제점 및 해결 방안**: 진행 중에 발생한 문제와 그에 대한 해결 방안을 공유합니다.\n",
      "4. **다음 단계**: 앞으로의 계획과 다음 단계에 대해 설명합니다.\n",
      "\n",
      "이런 정보를 공유하면 회의가 더 효과적으로 진행될 수 있습니다. 도움이 필요하시면 언제든지 말씀해 주세요!\n",
      "Human: 최근에 이야기 했던 새로운 기능에 대한 업데이트는 있어?\n",
      "AI: 새로운 기능에 대한 업데이트는 보통 팀 내에서 정기적으로 공유되거나, 개발팀에서 발표하는 경우가 많습니다. 만약 특정 기능에 대한 업데이트가 필요하시다면, 관련 팀원이나 담당자에게 직접 문의해 보시는 것이 좋습니다. \n",
      "\n",
      "또한, 회의에서 새로운 기능에 대한 진행 상황이나 피드백을 공유하는 것도 좋은 방법입니다. 이렇게 하면 팀원들이 최신 정보를 알고, 필요한 논의를 할 수 있습니다. 혹시 특정 기능에 대해 더 알고 싶으신 부분이 있다면 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "# user_d 세션에 대화내용을 기록 긴 대화 생성\n",
    "long_queries = [\n",
    "    '안녕, 오늘 우리 뭐하려고 했지?',\n",
    "    '아 맞다 내일 회의자료 준비해야지, 회의는 몇시지?',\n",
    "    '그 회의에 누가 참석하는지 기억나니?',\n",
    "    '단위 프로젝트 진행 상황도 공유해야 할까?',\n",
    "    '최근에 이야기 했던 새로운 기능에 대한 업데이트는 있어?'\n",
    "]\n",
    "\n",
    "session_id = 'user_d'\n",
    "for q in long_queries:\n",
    "    answer = chatbot.invoke({'input':q}, config={'configurable' : {'session_id': session_id}})\n",
    "\n",
    "\n",
    "print(f'요약전 user_d의 메모리 메세지 개수: {len(store[session_id].messages)}')\n",
    "print(store[session_id]) #요약하기전 대화 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b856fdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:50:16 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "== 요약 내용 ==\n",
      "대화 요약: \n",
      "사용자는 내일 회의 자료를 준비해야 한다고 언급하며 회의 시간과 참석자를 확인하려고 한다. AI는 회의 일정과 참석자 목록은 이메일이나 캘린더에서 확인할 수 있다고 안내하고, 단위 프로젝트 진행 상황을 공유하는 것이 좋다고 제안한다. AI는 회의에서 공유할 내용을 정리하는 방법을 제시하며, 필요한 경우 도움을 제공하겠다고 한다.\n"
     ]
    }
   ],
   "source": [
    "# 전체 대화 내용을 요약하고 마지막 사용자 질문-답변 쌍만 원본 유지\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "# 요약 대상 대화 내용 추출(마지막 QA 쌍 제외한 이전 내용)\n",
    "message = store[session_id].messages\n",
    "\n",
    "# 1번 주고받은 대화 이후에 또 했다는 것 -> 마지막을 빼야함\n",
    "if len(message) > 2 :\n",
    "    original_dialog = '\\n'.join([f'{msg.type.upper()} : {msg.content}' for msg in message[ : -2]])\n",
    "else : \n",
    "    original_dialog = '\\n'.join([f'{msg.type.upper()} : {msg.content}' for msg in message])\n",
    "\n",
    "# llm으로 요약 생성\n",
    "summary_text = summary_chain.invoke({'conversation' : original_dialog})\n",
    "print(\"== 요약 내용 ==\")\n",
    "print(summary_text)\n",
    "# 기존 메모리를 요약으로 교체 : 이전 내용 요약본 + 최근 QA 유지\n",
    "new_history = InMemoryChatMessageHistory()\n",
    "new_history.messages.append(SystemMessage(content = f'요약: {summary_text}'))\n",
    "\n",
    "# 최근 대화의 마지막 QA쌍 복원\n",
    "if len(message) >= 2 :\n",
    "    last_user_msg = message[-2]\n",
    "    last_ai_msg = message[-1]\n",
    "    # 휴먼 메시지인지 검사\n",
    "    if isinstance(last_user_msg, HumanMessage) :\n",
    "        new_history.add_user_message(last_user_msg.content)\n",
    "    else :\n",
    "        new_history.messages.append(last_user_msg)\n",
    "    if isinstance(last_ai_msg, AIMessage) :\n",
    "        new_history.add_ai_message(last_ai_msg.content)\n",
    "    else :\n",
    "        new_history.messages.append(last_ai_msg)\n",
    "# 메모리 교체\n",
    "store[session_id] = new_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c43183",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
